name: run_algoa-bay-forecast

on:
  workflow_dispatch:
    inputs:
      run_date:
        description: Run date "yyyymmdd". Default is today
        required: false
        default:
  schedule:
    - cron:  '0 2 * * *'

env:
  REGISTRY: ghcr.io
  COPERNICUS_USERNAME: ${{ secrets.COPERNICUS_USERNAME }}
  COPERNICUS_PASSWORD: ${{ secrets.COPERNICUS_PASSWORD }}
  GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}

jobs:
  # Dynamically set the branch ref to the currently executing branch
  branch-ref:
    runs-on: ubuntu-latest
    outputs:
      value: ${{ steps.BRANCH_REF.outputs.value }}
    steps:
    - name: Set the BRANCH_REF
      id: BRANCH_REF
      run: echo "::set-output name=value::${GITHUB_REF##*/}"

  # Many of the env variables reference the current branch
  # Set the environment variables using the current branch reference
  # (which is set dynamically)
  envs:
    needs: [branch-ref]
    runs-on: ubuntu-latest
    outputs:
      BRANCH_REF: ${{ needs.branch-ref.outputs.value }}
      CROCO_IMAGE: ${{ steps.ENVS.outputs.CROCO_IMAGE }}
      TOOLKIT_IMAGE: ${{ steps.ENVS.outputs.TOOLKIT_IMAGE }}
      MODEL_RUN_DATE: ${{ steps.ENVS.outputs.MODEL_RUN_DATE }}
      RESTART_FILE_DATE: ${{ steps.ENVS.outputs.RESTART_FILE_DATE }}
    steps:
      - name: Set envs
        id: ENVS
        run: |
          echo "::set-output name=CROCO_IMAGE::${{ github.repository }}_algoa_bay_forecast_croco_${{ needs.branch-ref.outputs.value }}"
          echo "::set-output name=TOOLKIT_IMAGE::${{ github.repository }}_algoa-bay-forecast_toolkit_${{ needs.branch-ref.outputs.value }}"
          echo "::set-output name=MODEL_RUN_DATE::$(date +'%Y%m%d')"
          echo "::set-output name=RESTART_FILE_DATE::$(date +'%Y%m%d' --date yesterday)"

  # # Some repository secrets are named according to the branch this action
  # # is executed from. As such the names of the secrets that need to be used
  # # in this workflow have to be set at runtime, using the current branch
  # # reference. But secrets can't be passed between jobs (since jobs may be
  # # executed on different servers). To allow for this, the secrets are 
  # # encrypted. Other jobs that use these secrets must decrypt them first
  # _secrets_:
  #   needs: [branch-ref]
  #   runs-on: ubuntu-latest
  #   outputs:
  #     PG_HOST_ENCRYPTED: ${{ steps.set-secrets.outputs.PG_HOST_ENCRYPTED }}
  #     PG_PORT_ENCRYPTED: ${{ steps.set-secrets.outputs.PG_PORT_ENCRYPTED }}
  #     PG_DB_ENCRYPTED: ${{ steps.set-secrets.outputs.PG_DB_ENCRYPTED }}
  #     PG_USERNAME_ENCRYPTED: ${{ steps.set-secrets.outputs.PG_USERNAME_ENCRYPTED }}
  #     PG_PASSWORD_ENCRYPTED: ${{ steps.set-secrets.outputs.PG_PASSWORD_ENCRYPTED }}
  #   steps:
  #     - name: Get PG_HOST secret name
  #       id: _PG_HOST_
  #       uses: ASzc/change-string-case-action@v2
  #       with:
  #         string: PG_HOST_${{ needs.branch-ref.outputs.value }}
  #     - name: Get PG_PORT secret name
  #       id: _PG_PORT_
  #       uses: ASzc/change-string-case-action@v2
  #       with:
  #         string: PG_PORT_${{ needs.branch-ref.outputs.value }}
  #     - name: Get PG_DB secret name
  #       id: _PG_DB_
  #       uses: ASzc/change-string-case-action@v2
  #       with:
  #         string: PG_DB_${{ needs.branch-ref.outputs.value }}
  #     - name: Get PG_USERNAME secret name
  #       id: _PG_USERNAME_
  #       uses: ASzc/change-string-case-action@v2
  #       with:
  #         string: PG_USERNAME_${{ needs.branch-ref.outputs.value }}
  #     - name: Get PG_PASSWORD secret name
  #       id: _PG_PASSWORD_
  #       uses: ASzc/change-string-case-action@v2
  #       with:
  #         string: PG_PASSWORD_${{ needs.branch-ref.outputs.value }}
  #     - name: Set secrets
  #       id: set-secrets
  #       run: |
  #         echo "::set-output name=PG_HOST_ENCRYPTED::$(gpg --symmetric --batch --passphrase "${{ env.GPG_PASSPHRASE }}" --output - <(echo "${{ secrets[steps._PG_HOST_.outputs.uppercase] }}") | base64 -w0)"
  #         echo "::set-output name=PG_PORT_ENCRYPTED::$(gpg --symmetric --batch --passphrase "${{ env.GPG_PASSPHRASE }}" --output - <(echo "${{ secrets[steps._PG_PORT_.outputs.uppercase] }}") | base64 -w0)"
  #         echo "::set-output name=PG_DB_ENCRYPTED::$(gpg --symmetric --batch --passphrase "${{ env.GPG_PASSPHRASE }}" --output - <(echo "${{ secrets[steps._PG_DB_.outputs.uppercase] }}") | base64 -w0)"
  #         echo "::set-output name=PG_USERNAME_ENCRYPTED::$(gpg --symmetric --batch --passphrase "${{ env.GPG_PASSPHRASE }}" --output - <(echo "${{ secrets[steps._PG_USERNAME_.outputs.uppercase] }}") | base64 -w0)"
  #         echo "::set-output name=PG_PASSWORD_ENCRYPTED::$(gpg --symmetric --batch --passphrase "${{ env.GPG_PASSPHRASE }}" --output - <(echo "${{ secrets[steps._PG_PASSWORD_.outputs.uppercase] }}") | base64 -w0)"

  # # Compile CROCO model for the Algoa Bay forecast
  # compile-model:
  #   needs: [envs]
  #   runs-on: ubuntu-latest
  #   env:
  #     BRANCH_REF: ${{ needs.envs.outputs.BRANCH_REF }}
  #     CROCO_IMAGE: ${{ needs.envs.outputs.CROCO_IMAGE }}
  #   outputs:
  #     image: ${{ steps.meta.outputs.tags }}
  #   steps:
  #     - name: Checkout source code
  #       uses: actions/checkout@v3
  #       with:
  #         ref: ${{ env.BRANCH_REF }}
  #     - name: Log in to the Container registry
  #       uses: docker/login-action@v1
  #       with:
  #         registry: ${{ env.REGISTRY }}
  #         username: ${{ github.actor }}
  #         password: ${{ secrets.GITHUB_TOKEN }}
  #     - name: Extract metadata (tags, labels) for Docker
  #       id: meta
  #       uses: docker/metadata-action@v3
  #       with:
  #         images: ${{ env.REGISTRY }}/${{ env.CROCO_IMAGE }}
  #         tags: |
  #           type=sha
  #     - name: Build and push
  #       uses: docker/build-push-action@v2
  #       with:
  #         context: models/algoa-bay-forecast
  #         file: models/algoa-bay-forecast/croco.Dockerfile
  #         push: true
  #         tags: ${{ steps.meta.outputs.tags }}
  #         labels: ${{ steps.meta.outputs.labels }}

  # # The SOMISANA toolkit is a suite of scripts to facilitate
  # # running SOMISANA models - for example the Algoa Bay Forecast.
  # # In the context of a testing environment, where updates to these
  # # scripts is part of the development workflow, the toolkit needs
  # # to be compiled on every run
  # bundle-python-toolkit:
  #   needs: [envs]
  #   runs-on: ubuntu-latest
  #   outputs:
  #     image: ${{ steps.meta.outputs.tags }}
  #   env:
  #     BRANCH_REF: ${{ needs.envs.outputs.BRANCH_REF }}
  #     TOOLKIT_IMAGE: ${{ needs.envs.outputs.TOOLKIT_IMAGE }}
  #   steps:
  #     - name: Check out source code
  #       uses: actions/checkout@v2
  #       with:
  #         ref: ${{ env.BRANCH_REF }}
  #     - name: Log in to the Container registry
  #       uses: docker/login-action@v1
  #       with:
  #         registry: ${{ env.REGISTRY }}
  #         username: ${{ github.actor }}
  #         password: ${{ secrets.GITHUB_TOKEN }}
  #     - name: Extract metadata (tags, labels) for Docker
  #       id: meta
  #       uses: docker/metadata-action@v3
  #       with:
  #         images: ${{ env.REGISTRY }}/${{ env.TOOLKIT_IMAGE }}
  #         tags: |
  #           type=sha
  #     - name: Build and push
  #       uses: docker/build-push-action@v2
  #       with:
  #         context: models/algoa-bay-forecast
  #         file: models/algoa-bay-forecast/toolkit.Dockerfile
  #         push: true
  #         tags: ${{ steps.meta.outputs.tags }}
  #         labels: ${{ steps.meta.outputs.labels }}

  # # Create a tmp folder structure for mode run assets. The format is:
  # ## YYYYMMDD/
  # ##  - forcing-inputs/
  # ##  - croco/
  # ##     - forcing/
  # ##     - forecast/
  # ##     - scratch/
  # working-directory:
  #   needs: [envs]
  #   runs-on: github-runner.saeon.int
  #   outputs:
  #     WORKDIR: ${{ steps.WORKDIR.outputs.WORKDIR}}
  #   env:
  #     dirname: ${{ needs.envs.outputs.MODEL_RUN_DATE }}
  #     branch_ref: ${{ needs.envs.outputs.BRANCH_REF }}
  #   steps:
  #     - name: Create /tmp/somisana/algoa-bay-forecast/${{ env.branch_ref }}/${{ env.dirname }} directory structure
  #       run: >-
  #         rm -rf /tmp/somisana/algoa-bay-forecast/${{ env.branch_ref }}/${{ env.dirname }} \
  #         && mkdir \
  #           -p \
  #           /tmp/somisana/algoa-bay-forecast/${{ env.branch_ref }}/${{ env.dirname }}/{croco/{forcing,forecast,scratch},forcing-inputs} \
  #         && chown \
  #           -R \
  #           :somisana \
  #           /tmp/somisana/algoa-bay-forecast/${{ env.branch_ref }}/${{ env.dirname }} \
  #         && chmod \
  #           -R \
  #           774 \
  #           /tmp/somisana/algoa-bay-forecast/${{ env.branch_ref }}/${{ env.dirname }}
  #     - name: Set $WORKDIR
  #       id: WORKDIR
  #       run: echo "::set-output name=WORKDIR::/tmp/somisana/algoa-bay-forecast/${{ env.branch_ref }}/${{ env.dirname }}"

  # # Download environmental data used to constrain model boundaries.
  # # These downloads are used to create forcing files that are fed as input to the CROCO model
  # # => marine.copernicus.eu: This is ocean data that forms the boundary of our model run
  # # => ncei.noaa.gov: This is weather data used to create sea-surface conditions for our model run
  # download-boundary-data:
  #   needs: [bundle-python-toolkit, working-directory]
  #   runs-on: github-runner.saeon.int
  #   env:
  #     WORKDIR: ${{ needs.working-directory.outputs.WORKDIR }}
  #   steps:
  #     - name: Download Algoa-bay forcing input
  #       run: >-
  #         docker run \
  #           --rm \
  #           -v $WORKDIR/:/tmp/somisana/current \
  #           -e COPERNICUS_USERNAME=${{ env.COPERNICUS_USERNAME }} \
  #           -e COPERNICUS_PASSWORD=${{ env.COPERNICUS_PASSWORD }} \
  #           ${{ needs.bundle-python-toolkit.outputs.image }} \
  #              download-boundary-data

  # # CROCOTOOLS is a collection of MatLab scripts for converting environmental data (i.e. the boundary data downloaded previously)
  # # into NetCDF files that can be used as input to the CROCO model. https://www.croco-ocean.org/documentation/crocotools-documentation/
  # make-forcings:
  #   needs: [download-boundary-data, working-directory, envs]
  #   runs-on: github-runner.saeon.int
  #   env:
  #     WORKDIR: ${{ needs.working-directory.outputs.WORKDIR }}
  #     RESTART_FILE_PATH: does_this_${{ needs.envs.outputs.RESTART_FILE_DATE }}_work?
  #     BRANCH_REF: ${{ needs.envs.outputs.BRANCH_REF }}
  #   steps:
  #     - name: Check out source code
  #       uses: actions/checkout@v2
  #       with:
  #         ref: ${{ env.BRANCH_REF }}
  #     - name: Configure restart file
  #       run: |
  #         echo "TODO Move yesterdays rst file if possible - $RESTART_FILE_PATH"
  #     - name: Make forcing files
  #       run: >-
  #         docker run \
  #           --rm \
  #           --mac-address 02:42:ff:ff:ff:ff \
  #           -v /opt/licenses/matlab-r2022a/license.lic:/licenses/license.lic \
  #           -v $(pwd)/models/algoa-bay-forecast/toolkit/make-forcings:/crocotools/ \
  #           -v $(pwd)/models/algoa-bay-forecast/lib/grd.nc:/crocotools/croco/forcing/grd.nc \
  #           -v $WORKDIR:/tmp/somisana/current \
  #           -e MLM_LICENSE_FILE=/licenses/license.lic \
  #           ghcr.io/saeon/somisana_matlab:r2022a \
  #             -batch "run('/crocotools/run.m')"

  # # Execute the CROCO model using the forcing files created previously
  # # The CROCO model executable is compiled a part of a Docker build, and is baked into a docker image.
  # # As such the CROCO model run must be in the context of a container instantiated from that Docker image
  # run-model:
  #   needs: [compile-model, make-forcings, envs, working-directory]
  #   runs-on: github-runner.saeon.int
  #   env:
  #     WORKDIR: ${{ needs.working-directory.outputs.WORKDIR }}
  #     BRANCH_REF: ${{ needs.envs.outputs.BRANCH_REF }}
  #   steps:
  #     - name: Check out source code
  #       uses: actions/checkout@v2
  #       with:
  #         ref: ${{ env.BRANCH_REF }}
  #     - name: Execute CROCO binary
  #       run: >-
  #         docker run \
  #           --rm \
  #           -v $WORKDIR:/algoa-bay-forecast/current \
  #           -v $(pwd)/models/algoa-bay-forecast/lib/grd.nc:/algoa-bay-forecast/current/croco/forcing/grd.nc \
  #           --cpus 10 \
  #           ${{ needs.compile-model.outputs.image }} \
  #             ./run_croco.bash \
  #               /algoa-bay-forecast/current \
  #               ${{ needs.envs.outputs.MODEL_RUN_DATE }} \
  #               ${{ needs.envs.outputs.RESTART_FILE_DATE }}

  # # The CROCO model outputs NetCDF data that represents ocean conditions of an
  # # area mapped to a grid. The post-processing step is for extracting data into
  # # a PostGIS instance where it is useful in the context of web applications
  # # (specifically as the backend of a WMS server)
  # process-model-output:
  #   needs: [bundle-python-toolkit, run-model, envs, working-directory]
  #   runs-on: github-runner.saeon.int
  #   env:
  #     WORKDIR: ${{ needs.working-directory.outputs.WORKDIR }}
  #     RUN_DATE: ${{ needs.envs.outputs.MODEL_RUN_DATE }}
  #   steps:
  #     - name: Check out source code
  #       uses: actions/checkout@v2
  #       with:
  #         ref: ${{ env.BRANCH_REF }}
  #     - name: Move CROCO output
  #       run: mv ${{ env.WORKDIR }}/croco/scratch/avg.nc ${{ env.WORKDIR }}/croco/forecast/avg-${{ env.RUN_DATE }}.nc
  #     - name: Algoa Bay forecast (post processing)
  #       run: >-
  #         docker run \
  #           --rm \
  #           -v $WORKDIR:/tmp/somisana/current \
  #           -v $(pwd)/models/algoa-bay-forecast/lib/grd.nc:/tmp/somisana/current/croco/forcing/grd.nc \
  #           ${{ needs.bundle-python-toolkit.outputs.image }} \
  #             post-processing \
  #               -g /tmp/somisana/current/croco/forcing/grd.nc \
  #               -i /tmp/somisana/current/croco/forecast/avg-${{ env.RUN_DATE }}.nc \
  #               -o /tmp/somisana/current/croco/forecast/avg-${{ env.RUN_DATE }}-processed.nc

  # # TODO - this will likely be to move the processed nc file
  # # to another server and configure WMS layers from it
  # handle-processed-data:
  #   needs: [process-model-output, working-directory, _secrets_]
  #   runs-on: github-runner.saeon.int
  #   env:
  #     WORKDIR: ${{ needs.working-directory.outputs.WORKDIR }}
  #   steps:
  #     - name: Decrypt secrets
  #       id: decrypt-secrets
  #       run: |
  #          echo "::set-output name=PG_HOST_DECRYPTED::$(gpg --decrypt --quiet --batch --passphrase "${{ env.GPG_PASSPHRASE }}" --output - <(echo "${{ needs._secrets_.outputs.PG_HOST_ENCRYPTED }}" | base64 --decode))"
  #          echo "::set-output name=PG_PORT_DECRYPTED::$(gpg --decrypt --quiet --batch --passphrase "${{ env.GPG_PASSPHRASE }}" --output - <(echo "${{ needs._secrets_.outputs.PG_PORT_ENCRYPTED }}" | base64 --decode))"
  #          echo "::set-output name=PG_DB_DECRYPTED::$(gpg --decrypt --quiet --batch --passphrase "${{ env.GPG_PASSPHRASE }}" --output - <(echo "${{ needs._secrets_.outputs.PG_DB_ENCRYPTED }}" | base64 --decode))"
  #          echo "::set-output name=PG_USERNAME_DECRYPTED::$(gpg --decrypt --quiet --batch --passphrase "${{ env.GPG_PASSPHRASE }}" --output - <(echo "${{ needs._secrets_.outputs.PG_USERNAME_ENCRYPTED }}" | base64 --decode))"
  #          echo "::set-output name=PG_PASSWORD_DECRYPTED::$(gpg --decrypt --quiet --batch --passphrase "${{ env.GPG_PASSPHRASE }}" --output - <(echo "${{ needs._secrets_.outputs.PG_PASSWORD_ENCRYPTED }}" | base64 --decode))"
  #     - name: Archive NetCDF files
  #       run: |
  #         echo "Where should we put the NetCDF (avg.nc) files?"
  #     - name: Update PostGIS
  #       env:
  #         PG_HOST: ${{ steps.decrypt-secrets.outputs.PG_HOST_DECRYPTED }}
  #         PG_PORT: ${{ steps.decrypt-secrets.outputs.PG_PORT_DECRYPTED }}
  #         PG_DB: ${{ steps.decrypt-secrets.outputs.PG_DB_DECRYPTED }}
  #         PG_USERNAME: ${{ steps.decrypt-secrets.outputs.PG_USERNAME_DECRYPTED }}
  #         PG_PASSWORD: ${{ steps.decrypt-secrets.outputs.PG_PASSWORD_DECRYPTED }}
  #       run: |
  #         echo "TODO"